{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree with MNIST model into block.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2eAuwsCEVO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the pydotplus package for visualizing decision trees\n",
        "!pip install pydotplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xubCV_juFi8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standard Libraries\n",
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import random as rn\n",
        "\n",
        "# Visualization libraries\n",
        "import pydotplus\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style({\"axes.facecolor\": \".95\"})\n",
        "\n",
        "# Modeling and Machine Learning\n",
        "from IPython.display import Image \n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals.six import StringIO  \n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "# Specify Paths for easy dataloading\n",
        "BASE_PATH = '../input/'\n",
        "TRAIN_PATH = BASE_PATH + 'train.csv'\n",
        "TEST_PATH = BASE_PATH + 'test.csv'\n",
        "\n",
        "# Seed for reproducability\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "rn.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tC4BQoHFi_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File sizes and specifications\n",
        "print('\\n# Files and file sizes')\n",
        "for file in os.listdir(BASE_PATH):\n",
        "    print('{}| {} MB'.format(file.ljust(30), \n",
        "                             str(round(os.path.getsize(BASE_PATH + file) / 1000000, 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kAqPxS9Fq8t",
        "colab_type": "text"
      },
      "source": [
        "# **Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTQ9dRR7FjB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load in training and testing data\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df = pd.read_csv(TEST_PATH)\n",
        "concat_df = pd.concat([train_df, test_df])\n",
        "sample_sub = pd.read_csv(BASE_PATH + 'sample_submission.csv');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dgJIAPYF4WY",
        "colab_type": "text"
      },
      "source": [
        "**Metric**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8mW_QA1FjEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def acc(y_true : np.ndarray, y_pred : np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "        Calculates the accuracy score between labels and predictions.\n",
        "        \n",
        "        :param y_true: The true labels of the data\n",
        "        :param y_pred: The predictions for the data\n",
        "        \n",
        "        :return: a floating point number denoting the accuracy\n",
        "    \"\"\"\n",
        "    return round(accuracy_score(y_true, y_pred) * 100, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gab2VyRwGBCO",
        "colab_type": "text"
      },
      "source": [
        "# **Baseline Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_vYivQcFjGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all pixel features\n",
        "features = [col for col in train_df.columns if col.startswith('pixel')]\n",
        "# Split up training to for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_df[features], \n",
        "                                                  train_df['label'], \n",
        "                                                  test_size=0.25, \n",
        "                                                  random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMcUK5xBFjJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train baseline decision tree model\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBgAmD9pFjN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the baseline model\n",
        "train_preds_baseline = clf.predict(X_train)\n",
        "val_preds_baseline = clf.predict(X_val)\n",
        "acc_baseline_train = acc(train_preds_baseline, y_train)\n",
        "acc_baseline_val = acc(val_preds_baseline, y_val)\n",
        "print(f'Training accuracy for our baseline (using all pixel features): {acc_baseline_train}%')\n",
        "print(f'Validation accuracy for our baseline (using all pixel features): {acc_baseline_val}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s6m0fpXFjQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Decision Tree to visualization\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, \n",
        "                max_depth=3)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qxg5A0OGZsq",
        "colab_type": "text"
      },
      "source": [
        "**Dimensionality Reduction (TSVD and t-SNE)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcN8INPcFjUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform Truncated Singular Value Decomposition (TSVD) on all features\n",
        "# This will reduce the amount of features to 50 and will simplify t-SNE\n",
        "tsvd = TruncatedSVD(n_components=50).fit_transform(concat_df[features])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6q4iz1HFjX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split up the t-SNE results in training and testing data\n",
        "tsvd_cols = [f'component_{i+1}' for i in range(50)]\n",
        "tsvd_train = pd.DataFrame(tsvd[:len(train_df)], columns=[tsvd_cols])\n",
        "tsvd_test = pd.DataFrame(tsvd[len(train_df):], columns=[tsvd_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeqAeY25Fja7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform another split for t-sne feature validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(tsvd_train, \n",
        "                                                  train_df['label'], \n",
        "                                                  test_size=0.25, \n",
        "                                                  random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUZj3yeCFjdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model with t-svd features\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_n10LIzFjgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model with the 50 TSVD features and compare to the baseline model\n",
        "train_preds = clf.predict(X_train)\n",
        "val_preds = clf.predict(X_val)\n",
        "acc_tsvd_train = acc(train_preds, y_train)\n",
        "acc_tsvd_val = acc(val_preds, y_val)\n",
        "print(f'Training accuracy with TSVD features (50 components): {acc_tsvd_train}%')\n",
        "print(f'Validation accuracy with TSVD features (50 components): {acc_tsvd_val}%')\n",
        "# Check out how it performed compared to the baseline\n",
        "acc_diff = round(acc_tsvd_val - acc_baseline_val, 2)\n",
        "print(f'\\nThis is a difference of {acc_diff}% in validation accuracy compared to the baseline.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yk4DiOXFjjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit t-SNE on the Truncated SVD reduced data (50 features)\n",
        "tsne = TSNE()\n",
        "transformed = tsne.fit_transform(tsvd)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcA-zpTzGp4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split up the t-SNE results in training and testing data\n",
        "tsne_train = pd.DataFrame(transformed[:len(train_df)], columns=['component1', 'component2'])\n",
        "tsne_test = pd.DataFrame(transformed[len(train_df):], columns=['component1', 'component2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrL7JZofG7C-",
        "colab_type": "text"
      },
      "source": [
        "# **Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-se9w5hG4tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform another split for t-sne feature validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(tsne_train, \n",
        "                                                  train_df['label'], \n",
        "                                                  test_size=0.25, \n",
        "                                                  random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaii6uS3Gp-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model with t-sne features\n",
        "clf = DecisionTreeClassifier(max_depth=10, random_state=seed)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aELhFGkoFjmD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert Decision Tree to visualization\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, \n",
        "                max_depth=3)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M011jj8hFjMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate model with t-SNE features and compare to the baseline model\n",
        "train_preds = clf.predict(X_train)\n",
        "val_preds = clf.predict(X_val)\n",
        "acc_tsne_train = acc(train_preds, y_train)\n",
        "acc_tsne_val = acc(val_preds, y_val)\n",
        "print(f'Training accuracy with t-SNE features: {acc_tsne_train}%')\n",
        "print(f'Validation accuracy with t-SNE features: {acc_tsne_val}%')\n",
        "# Compare t-SNE results with the baseline model\n",
        "acc_diff = round(acc_tsne_val - acc_baseline_val, 2)\n",
        "print(f'\\nThis is an improvement of {acc_diff}% in validation accuracy over the baseline!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8NKwkn_HHPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "file = open(\"decision.pkl\",'wb')\n",
        "pickle.dump(clf, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTRciXohDcrf",
        "colab_type": "text"
      },
      "source": [
        "# **Convert pkl to json and load into block** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qsRLj_DDvix",
        "colab_type": "text"
      },
      "source": [
        "##**BLOCK ADDING TO CHAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxfaiU_xHXPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hashlib import sha256\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "class Block:\n",
        "    def __init__(self, index, transactions, timestamp, previous_hash):\n",
        "        self.index = index\n",
        "        self.transactions = transactions\n",
        "        self.timestamp = timestamp\n",
        "        self.previous_hash = previous_hash\n",
        "        self.nonce = 0\n",
        "\n",
        "    def compute_hash(self):\n",
        "        \"\"\"\n",
        "        A function that return the hash of the block contents.\n",
        "        \"\"\"\n",
        "        block_string = json.dumps(self.__dict__, sort_keys=True)\n",
        "        return sha256(block_string.encode()).hexdigest()\n",
        "\n",
        "\n",
        "class Blockchain:\n",
        "    # difficulty of our PoW algorithm\n",
        "    difficulty = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        self.unconfirmed_transactions = []\n",
        "        self.chain = []\n",
        "        self.create_genesis_block()\n",
        "\n",
        "    def create_genesis_block(self):\n",
        "        \"\"\"\n",
        "        A function to generate genesis block and appends it to\n",
        "        the chain. The block has index 0, previous_hash as 0, and\n",
        "        a valid hash.\n",
        "        \"\"\"\n",
        "        genesis_block = Block(0, [], time.time(), \"0\")\n",
        "        genesis_block.hash = genesis_block.compute_hash()\n",
        "        self.chain.append(genesis_block)\n",
        "\n",
        "    @property\n",
        "    def last_block(self):\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def add_block(self, block, proof):\n",
        "        \"\"\"\n",
        "        A function that adds the block to the chain after verification.\n",
        "        Verification includes:\n",
        "        * Checking if the proof is valid.\n",
        "        * The previous_hash referred in the block and the hash of latest block\n",
        "          in the chain match.\n",
        "        \"\"\"\n",
        "        previous_hash = self.last_block.hash\n",
        "\n",
        "        if previous_hash != block.previous_hash:\n",
        "            return False\n",
        "\n",
        "        if not self.is_valid_proof(block, proof):\n",
        "            return False\n",
        "\n",
        "        block.hash = proof\n",
        "        self.chain.append(block)\n",
        "        chain_data = []\n",
        "        for block in blockchain.chain:\n",
        "            chain_data.append(block.__dict__)\n",
        "        with open('data.json', 'w') as json_file:\n",
        "            json.dump({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data}, json_file)\n",
        "        return True\n",
        "\n",
        "    def is_valid_proof(self, block, block_hash):\n",
        "        \"\"\"\n",
        "        Check if block_hash is valid hash of block and satisfies\n",
        "        the difficulty criteria.\n",
        "        \"\"\"\n",
        "        return (block_hash.startswith('0' * Blockchain.difficulty) and\n",
        "                block_hash == block.compute_hash())\n",
        "\n",
        "    def proof_of_work(self, block):\n",
        "        \"\"\"\n",
        "        Function that tries different values of nonce to get a hash\n",
        "        that satisfies our difficulty criteria.\n",
        "        \"\"\"\n",
        "        block.nonce = 0\n",
        "\n",
        "        computed_hash = block.compute_hash()\n",
        "        while not computed_hash.startswith('0' * Blockchain.difficulty):\n",
        "            block.nonce += 1\n",
        "            computed_hash = block.compute_hash()\n",
        "\n",
        "        return computed_hash\n",
        "\n",
        "    def add_new_transaction(self, transaction):\n",
        "        self.unconfirmed_transactions.append(transaction)\n",
        "\n",
        "    def mine(self):\n",
        "        \"\"\"\n",
        "        This function serves as an interface to add the pending\n",
        "        transactions to the blockchain by adding them to the block\n",
        "        and figuring out Proof Of Work.\n",
        "        \"\"\"\n",
        "        if not self.unconfirmed_transactions:\n",
        "            return False\n",
        "\n",
        "        last_block = self.last_block\n",
        "\n",
        "        new_block = Block(index=last_block.index + 1,\n",
        "                          transactions=self.unconfirmed_transactions,\n",
        "                          timestamp=time.time(),\n",
        "                          previous_hash=last_block.hash)\n",
        "\n",
        "        proof = self.proof_of_work(new_block)\n",
        "        self.add_block(new_block, proof)\n",
        "\n",
        "        self.unconfirmed_transactions = []\n",
        "        return new_block.index\n",
        "blockchain = Blockchain()\n",
        "tx_data = model_json\n",
        "blockchain.add_new_transaction(tx_data)\n",
        "blockchain.mine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuwzhzrUEBJI",
        "colab_type": "text"
      },
      "source": [
        "# **WRITING TIME CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX7AT56NHkO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "header = 'W'\n",
        "file = open('Writing_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    blockchain = Blockchain()\n",
        "    tx_data = model_json\n",
        "    blockchain.add_new_transaction(tx_data)\n",
        "    blockchain.mine()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Writing_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pYTGW8-BHmKl"
      },
      "source": [
        "# **READING TIME CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ4HwQLCHwEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_chain():\n",
        "    chain_data = []\n",
        "    for block in blockchain.chain:\n",
        "        chain_data.append(block.__dict__)\n",
        "    return json.dumps({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data})\n",
        "header = 'R'\n",
        "file = open('Reading_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    get_chain()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Reading_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}