{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Neural Network with MNIST_Keras into block.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6mQB-FW9aPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt # plotting library\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation, Dropout\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras import  backend as K\n",
        "\n",
        "\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zl6qGDx-A1J",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT DATASET**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aaS9Tnp9qMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dataset\n",
        "from keras.datasets import mnist\n",
        "\n",
        "\n",
        "# load dataset\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# count the number of unique train labels\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(\"Train labels: \", dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "\n",
        "# count the number of unique test labels\n",
        "unique, counts = np.unique(y_test, return_counts=True)\n",
        "print(\"\\nTest labels: \", dict(zip(unique, counts)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD3-erHM-XT-",
        "colab_type": "text"
      },
      "source": [
        "## **DATA VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQCLF0X297lD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample 25 mnist digits from train dataset\n",
        "indexes = np.random.randint(0, x_train.shape[0], size=25)\n",
        "images = x_train[indexes]\n",
        "labels = y_train[indexes]\n",
        "\n",
        "\n",
        "# plot the 25 mnist digits\n",
        "plt.figure(figsize=(5,5))\n",
        "for i in range(len(indexes)):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    image = images[i]\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    \n",
        "plt.show()\n",
        "plt.savefig(\"mnist-samples.png\")\n",
        "plt.close('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwH7W33k-kcz",
        "colab_type": "text"
      },
      "source": [
        "IMPORT KERAS LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGP6lPsG-gXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.utils import to_categorical, plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0EIX7zT-gaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the number of labels\n",
        "num_labels = len(np.unique(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QFEqa7u-ggT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to one-hot vector\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED55pm7D-gi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image dimensions (assumed square)\n",
        "image_size = x_train.shape[1]\n",
        "input_size = image_size * image_size\n",
        "input_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90L-nKw---VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# resize and normalize\n",
        "x_train = np.reshape(x_train, [-1, input_size])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = np.reshape(x_test, [-1, input_size])\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2WOyDwr_ADE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network parameters\n",
        "batch_size = 128\n",
        "hidden_units = 256\n",
        "dropout = 0.45"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfkcevwl_DFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model is a 3-layer MLP with ReLU and dropout after each layer\n",
        "model = Sequential()\n",
        "model.add(Dense(hidden_units, input_dim=input_size))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(hidden_units))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sdq25dF_DH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYZMq4bA_DKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(model, to_file='mlp-mnist.png', show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-o0JN7M_DNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekkT_HcG_DTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=20, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZW2Lznr-_MYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZeWEG-4_MbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"SDN_nn.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save_weights(\"SDN_nn.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGhTBq1ZCVyB",
        "colab_type": "text"
      },
      "source": [
        "# **BLOCK ADDING TO CHAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QnWfDDQ_MeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from hashlib import sha256\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "class Block:\n",
        "    def __init__(self, index, transactions, timestamp, previous_hash):\n",
        "        self.index = index\n",
        "        self.transactions = transactions\n",
        "        self.timestamp = timestamp\n",
        "        self.previous_hash = previous_hash\n",
        "        self.nonce = 0\n",
        "\n",
        "    def compute_hash(self):\n",
        "        \"\"\"\n",
        "        A function that return the hash of the block contents.\n",
        "        \"\"\"\n",
        "        block_string = json.dumps(self.__dict__, sort_keys=True)\n",
        "        return sha256(block_string.encode()).hexdigest()\n",
        "\n",
        "\n",
        "class Blockchain:\n",
        "    # difficulty of our PoW algorithm\n",
        "    difficulty = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        self.unconfirmed_transactions = []\n",
        "        self.chain = []\n",
        "        self.create_genesis_block()\n",
        "\n",
        "    def create_genesis_block(self):\n",
        "        \"\"\"\n",
        "        A function to generate genesis block and appends it to\n",
        "        the chain. The block has index 0, previous_hash as 0, and\n",
        "        a valid hash.\n",
        "        \"\"\"\n",
        "        genesis_block = Block(0, [], time.time(), \"0\")\n",
        "        genesis_block.hash = genesis_block.compute_hash()\n",
        "        self.chain.append(genesis_block)\n",
        "\n",
        "    @property\n",
        "    def last_block(self):\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def add_block(self, block, proof):\n",
        "        \"\"\"\n",
        "        A function that adds the block to the chain after verification.\n",
        "        Verification includes:\n",
        "        * Checking if the proof is valid.\n",
        "        * The previous_hash referred in the block and the hash of latest block\n",
        "          in the chain match.\n",
        "        \"\"\"\n",
        "        previous_hash = self.last_block.hash\n",
        "\n",
        "        if previous_hash != block.previous_hash:\n",
        "            return False\n",
        "\n",
        "        if not self.is_valid_proof(block, proof):\n",
        "            return False\n",
        "\n",
        "        block.hash = proof\n",
        "        self.chain.append(block)\n",
        "        chain_data = []\n",
        "        for block in blockchain.chain:\n",
        "            chain_data.append(block.__dict__)\n",
        "        with open('data.json', 'w') as json_file:\n",
        "            json.dump({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data}, json_file)\n",
        "        return True\n",
        "\n",
        "    def is_valid_proof(self, block, block_hash):\n",
        "        \"\"\"\n",
        "        Check if block_hash is valid hash of block and satisfies\n",
        "        the difficulty criteria.\n",
        "        \"\"\"\n",
        "        return (block_hash.startswith('0' * Blockchain.difficulty) and\n",
        "                block_hash == block.compute_hash())\n",
        "\n",
        "    def proof_of_work(self, block):\n",
        "        \"\"\"\n",
        "        Function that tries different values of nonce to get a hash\n",
        "        that satisfies our difficulty criteria.\n",
        "        \"\"\"\n",
        "        block.nonce = 0\n",
        "\n",
        "        computed_hash = block.compute_hash()\n",
        "        while not computed_hash.startswith('0' * Blockchain.difficulty):\n",
        "            block.nonce += 1\n",
        "            computed_hash = block.compute_hash()\n",
        "\n",
        "        return computed_hash\n",
        "\n",
        "    def add_new_transaction(self, transaction):\n",
        "        self.unconfirmed_transactions.append(transaction)\n",
        "\n",
        "    def mine(self):\n",
        "        \"\"\"\n",
        "        This function serves as an interface to add the pending\n",
        "        transactions to the blockchain by adding them to the block\n",
        "        and figuring out Proof Of Work.\n",
        "        \"\"\"\n",
        "        if not self.unconfirmed_transactions:\n",
        "            return False\n",
        "\n",
        "        last_block = self.last_block\n",
        "\n",
        "        new_block = Block(index=last_block.index + 1,\n",
        "                          transactions=self.unconfirmed_transactions,\n",
        "                          timestamp=time.time(),\n",
        "                          previous_hash=last_block.hash)\n",
        "\n",
        "        proof = self.proof_of_work(new_block)\n",
        "        self.add_block(new_block, proof)\n",
        "\n",
        "        self.unconfirmed_transactions = []\n",
        "        return new_block.index\n",
        "blockchain = Blockchain()\n",
        "tx_data = model_json\n",
        "blockchain.add_new_transaction(tx_data)\n",
        "blockchain.mine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtmhkYT3Ccv3",
        "colab_type": "text"
      },
      "source": [
        "# **WRITING TIME CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL2QP0vq_Mg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "header = 'W'\n",
        "file = open('Writing_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    blockchain = Blockchain()\n",
        "    tx_data = model_json\n",
        "    blockchain.add_new_transaction(tx_data)\n",
        "    blockchain.mine()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Writing_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUgrHgQCkBC",
        "colab_type": "text"
      },
      "source": [
        "# **READING TIME CSV**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blRI3Wzi_Mj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_chain():\n",
        "    chain_data = []\n",
        "    for block in blockchain.chain:\n",
        "        chain_data.append(block.__dict__)\n",
        "    return json.dumps({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data})\n",
        "header = 'R'\n",
        "file = open('Reading_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    get_chain()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Reading_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}