{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Bayes with MNIST model into block.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcZVy1pbbsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow import keras\n",
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AofrzErRdDiY",
        "colab_type": "text"
      },
      "source": [
        "# **Preparation and Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KskofGEwc92C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = keras.datasets.mnist\n",
        "\n",
        "(X_raw_train, y_train), (X_raw_test, y_test) = dataset.load_data()\n",
        "\n",
        "X_train = np.zeros((X_raw_train.shape[0], 108))\n",
        "X_test = np.zeros((X_raw_test.shape[0], 108))\n",
        "\n",
        "hog = cv2.HOGDescriptor((28, 28), (14, 14), (7, 7), (14, 14), 12)\n",
        "\n",
        "for n in range(X_raw_train.shape[0]):\n",
        "    X_train[n] = hog.compute(X_raw_train[n]).reshape(1, -1)\n",
        "    \n",
        "for n in range(X_raw_test.shape[0]):\n",
        "    X_test[n] = hog.compute(X_raw_test[n]).reshape(1, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQiAAo5Ic96J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, ax = plt.subplots(8, 8, figsize=(10, 10))\n",
        "index = 0\n",
        "\n",
        "for i in range(8):\n",
        "    for j in range(8):\n",
        "        cell = ax[i][j]\n",
        "        cell.set_xticks([])\n",
        "        cell.set_yticks([])\n",
        "        cell.grid(False)\n",
        "        cell.imshow(X_raw_test[index], cmap='gray')\n",
        "        index += 1\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d923Fp6dQ3l",
        "colab_type": "text"
      },
      "source": [
        "Now let's calculate the prior probability p(y). This will actually be a vector containing the probabilities of occurrence for each class in our dataset. That is, the numbers from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg_JVPWfc98j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, prob_y = np.unique(y_train, return_counts=True)\n",
        "prob_y = prob_y / len(y_train)\n",
        "num_classes = len(prob_y)\n",
        "prob_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck9n3URcdfxF",
        "colab_type": "text"
      },
      "source": [
        "Calculating the Log of the Gaussian likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQssMzVc9_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_gaussian(X, mu, sigma):\n",
        "    return -(np.sum(np.log(sigma)) + 0.5 * np.sum(((X - mu) / sigma) ** 2)).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtQof52ddnd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_naive_bayes():\n",
        "    means = np.zeros((num_classes, X_train.shape[1]), dtype=np.float64)\n",
        "    stdevs = np.zeros((num_classes, X_train.shape[1]), dtype=np.float64)\n",
        "    \n",
        "    for k, y_k in enumerate(np.unique(y_train)):\n",
        "        indices = np.where(y_k == y_train)\n",
        "        means[k] = np.mean(X_train[indices], axis=0)\n",
        "        stdevs[k] = np.std(X_train[indices], axis=0)\n",
        "        \n",
        "    return means, stdevs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M47dUKxfc-CD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "means, stdevs = train_naive_bayes()\n",
        "print('Means for class 0:\\n', means[0], '\\n\\nStandard deviations for class 0\\n', stdevs[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH2lSAsJdnKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(x):\n",
        "    return np.argmax([np.log(prob_y[k]) + log_gaussian(x.reshape(1, -1), \n",
        "                      means[k], stdevs[k]) for k in range(num_classes)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAgRW6M4d7sI",
        "colab_type": "text"
      },
      "source": [
        "Finding the accuracy of our model by predicting the y value for each image in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlM-haIidnNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = np.zeros((X_test.shape[0]))\n",
        "\n",
        "for n in range(X_test.shape[0]):\n",
        "    y_pred[n] = predict(X_test[n])\n",
        "\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du3ohvFddnGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, ax = plt.subplots(6, 8, figsize=(10, 10))\n",
        "index = 0\n",
        "\n",
        "for i in range(6):\n",
        "    for j in range(8):\n",
        "        cell = ax[i][j]\n",
        "        cell.set_title('Pred: %s' % predict(X_test[index]))\n",
        "        cell.set_xticks([])\n",
        "        cell.set_yticks([])\n",
        "        cell.grid(False)\n",
        "        cell.imshow(X_raw_test[index], cmap='gray')\n",
        "        index += 1\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cFfRJPVeEt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVK4oLfpeEfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2dx6xNfeEa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_Os77qleT5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "file = open(\"model_nb.pkl\",'wb')\n",
        "pickle.dump(model, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xwu8HzhgbKXL"
      },
      "source": [
        "# **Convert pkl to json and load into block** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cMUfODUybKXN"
      },
      "source": [
        "##**BLOCK ADDING TO CHAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "twjwkiMxbKXN",
        "colab": {}
      },
      "source": [
        "from hashlib import sha256\n",
        "import json\n",
        "import time\n",
        "\n",
        "\n",
        "class Block:\n",
        "    def __init__(self, index, transactions, timestamp, previous_hash):\n",
        "        self.index = index\n",
        "        self.transactions = transactions\n",
        "        self.timestamp = timestamp\n",
        "        self.previous_hash = previous_hash\n",
        "        self.nonce = 0\n",
        "\n",
        "    def compute_hash(self):\n",
        "        \"\"\"\n",
        "        A function that return the hash of the block contents.\n",
        "        \"\"\"\n",
        "        block_string = json.dumps(self.__dict__, sort_keys=True)\n",
        "        return sha256(block_string.encode()).hexdigest()\n",
        "\n",
        "\n",
        "class Blockchain:\n",
        "    # difficulty of our PoW algorithm\n",
        "    difficulty = 2\n",
        "\n",
        "    def __init__(self):\n",
        "        self.unconfirmed_transactions = []\n",
        "        self.chain = []\n",
        "        self.create_genesis_block()\n",
        "\n",
        "    def create_genesis_block(self):\n",
        "        \"\"\"\n",
        "        A function to generate genesis block and appends it to\n",
        "        the chain. The block has index 0, previous_hash as 0, and\n",
        "        a valid hash.\n",
        "        \"\"\"\n",
        "        genesis_block = Block(0, [], time.time(), \"0\")\n",
        "        genesis_block.hash = genesis_block.compute_hash()\n",
        "        self.chain.append(genesis_block)\n",
        "\n",
        "    @property\n",
        "    def last_block(self):\n",
        "        return self.chain[-1]\n",
        "\n",
        "    def add_block(self, block, proof):\n",
        "        \"\"\"\n",
        "        A function that adds the block to the chain after verification.\n",
        "        Verification includes:\n",
        "        * Checking if the proof is valid.\n",
        "        * The previous_hash referred in the block and the hash of latest block\n",
        "          in the chain match.\n",
        "        \"\"\"\n",
        "        previous_hash = self.last_block.hash\n",
        "\n",
        "        if previous_hash != block.previous_hash:\n",
        "            return False\n",
        "\n",
        "        if not self.is_valid_proof(block, proof):\n",
        "            return False\n",
        "\n",
        "        block.hash = proof\n",
        "        self.chain.append(block)\n",
        "        chain_data = []\n",
        "        for block in blockchain.chain:\n",
        "            chain_data.append(block.__dict__)\n",
        "        with open('data.json', 'w') as json_file:\n",
        "            json.dump({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data}, json_file)\n",
        "        return True\n",
        "\n",
        "    def is_valid_proof(self, block, block_hash):\n",
        "        \"\"\"\n",
        "        Check if block_hash is valid hash of block and satisfies\n",
        "        the difficulty criteria.\n",
        "        \"\"\"\n",
        "        return (block_hash.startswith('0' * Blockchain.difficulty) and\n",
        "                block_hash == block.compute_hash())\n",
        "\n",
        "    def proof_of_work(self, block):\n",
        "        \"\"\"\n",
        "        Function that tries different values of nonce to get a hash\n",
        "        that satisfies our difficulty criteria.\n",
        "        \"\"\"\n",
        "        block.nonce = 0\n",
        "\n",
        "        computed_hash = block.compute_hash()\n",
        "        while not computed_hash.startswith('0' * Blockchain.difficulty):\n",
        "            block.nonce += 1\n",
        "            computed_hash = block.compute_hash()\n",
        "\n",
        "        return computed_hash\n",
        "\n",
        "    def add_new_transaction(self, transaction):\n",
        "        self.unconfirmed_transactions.append(transaction)\n",
        "\n",
        "    def mine(self):\n",
        "        \"\"\"\n",
        "        This function serves as an interface to add the pending\n",
        "        transactions to the blockchain by adding them to the block\n",
        "        and figuring out Proof Of Work.\n",
        "        \"\"\"\n",
        "        if not self.unconfirmed_transactions:\n",
        "            return False\n",
        "\n",
        "        last_block = self.last_block\n",
        "\n",
        "        new_block = Block(index=last_block.index + 1,\n",
        "                          transactions=self.unconfirmed_transactions,\n",
        "                          timestamp=time.time(),\n",
        "                          previous_hash=last_block.hash)\n",
        "\n",
        "        proof = self.proof_of_work(new_block)\n",
        "        self.add_block(new_block, proof)\n",
        "\n",
        "        self.unconfirmed_transactions = []\n",
        "        return new_block.index\n",
        "blockchain = Blockchain()\n",
        "tx_data = model_json\n",
        "blockchain.add_new_transaction(tx_data)\n",
        "blockchain.mine()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERNeoBJVbKXU"
      },
      "source": [
        "# **WRITING TIME CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yq-teU6AbKXV",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "header = 'W'\n",
        "file = open('Writing_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    blockchain = Blockchain()\n",
        "    tx_data = model_json\n",
        "    blockchain.add_new_transaction(tx_data)\n",
        "    blockchain.mine()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Writing_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RTCdSjDAbKXX"
      },
      "source": [
        "# **READING TIME CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yKnxE6P4bKXY",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_chain():\n",
        "    chain_data = []\n",
        "    for block in blockchain.chain:\n",
        "        chain_data.append(block.__dict__)\n",
        "    return json.dumps({\"length\": len(chain_data),\n",
        "                       \"chain\": chain_data})\n",
        "header = 'R'\n",
        "file = open('Reading_Time.csv', 'w', newline='')\n",
        "with file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "for i in range(0,50):\n",
        "    start_time = time.time()\n",
        "    get_chain()\n",
        "    end_time = time.time() - start_time\n",
        "    to_append = f'{end_time}'    \n",
        "    file = open('Reading_Time.csv', 'a', newline='')\n",
        "    with file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow(to_append.split())\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}